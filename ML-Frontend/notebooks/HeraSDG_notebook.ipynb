{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "approved-sweden",
   "metadata": {},
   "source": [
    "# PREPROCESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-tension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "individual-mexico",
   "metadata": {},
   "source": [
    "### 1. Create the Spark Session and Spark Context\n",
    "The Spark session is the entry point into all functionality in Spark.\n",
    "You can custom your session with spark.configuration using *.config(\"spark.some.config.option\", \"some-value\")*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Preprocessor\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create a context from the specified session\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-birmingham",
   "metadata": {},
   "source": [
    "### 2. Load data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "white-oasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#First obtain the current time\n",
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "current_year = str(now.year)\n",
    "current_mont = str(now.month)\n",
    "current_day  = str(now.day) #attenzione che qui restituisce 3 ma hdfs vuole 03! Idem per le ore.\n",
    "current_hour = str(now.hour)\n",
    "print(now.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "smart-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data of the last nn hours\n",
    "\n",
    "# The path can be either a single text file or a directory storing text files\n",
    "utenti_path = \"hdfs://my-hdfs-namenodes:8020/HeraSDG/raw_data/utenti/*/*/*/*/*.json\"\n",
    "comportamenti_path = \"hdfs://my-hdfs-namenodes:8020/HeraSDG/raw_data/comportamenti/*/*/*/*/*.json\"\n",
    "premi_path = \"hdfs://my-hdfs-namenodes:8020/HeraSDG/raw_data/premi/*/*/*/*/*.json\"\n",
    "utenti = spark.read.json(utenti_path)\n",
    "comportamenti = spark.read.json(comportamenti_path)\n",
    "premi = spark.read.json(premi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naked-cartridge",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Data di Nascita: string (nullable = true)\n",
      " |-- Eta: long (nullable = true)\n",
      " |-- Provincia: string (nullable = true)\n",
      " |-- Sesso: string (nullable = true)\n",
      " |-- id_utente: string (nullable = true)\n",
      "\n",
      "+-------+---------------+------------------+---------+-----+---------+\n",
      "|summary|Data di Nascita|               Eta|Provincia|Sesso|id_utente|\n",
      "+-------+---------------+------------------+---------+-----+---------+\n",
      "|  count|          30609|             30609|    30609|30609|    30609|\n",
      "|   mean|           null|54.232905354634255|     null| null|     null|\n",
      "| stddev|           null| 20.99087701181164|     null| null|     null|\n",
      "|    min|     1930-03-31|                18|         |     |         |\n",
      "|    max|     2003-03-29|                90|       RE|    M|  HE_9999|\n",
      "+-------+---------------+------------------+---------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utenti.printSchema()\n",
    "utenti.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "floppy-aircraft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+---------+----------+\n",
      "|Partner_erogante|       comportamento|id_utente|reward(tk)|\n",
      "+----------------+--------------------+---------+----------+\n",
      "|            HERA|Acquisto energia ...|  CA_2687|      2.85|\n",
      "|            HERA|Autolettura consu...|   HE_267|       1.6|\n",
      "|            HERA|Acquisto energia ...|    HE_32|      2.85|\n",
      "|           CONAD|Acquisto di prodo...|  CO_3281|      2.55|\n",
      "|            HERA|Invio elettronico...|   CO_522|      1.75|\n",
      "+----------------+--------------------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comportamenti.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "romance-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+--------------------+----------+\n",
      "|Partner_erogante|id_utente|              premio|prezzo(tk)|\n",
      "+----------------+---------+--------------------+----------+\n",
      "|           CONAD|  CA_1935|Buono Spesa 5€ Conad|         5|\n",
      "|           CAMST|  HE_1994|Buono Spesa 5€ Camst|         5|\n",
      "|           CONAD|  HE_1799|Buono Spesa 5€ Conad|         5|\n",
      "|           CONAD|  CA_2284|Buono Spesa 5€ Conad|         5|\n",
      "|           CONAD|   CA_627|Buono Spesa 5€ Conad|        10|\n",
      "+----------------+---------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "premi.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-mount",
   "metadata": {},
   "source": [
    "### 3. Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-physics",
   "metadata": {},
   "source": [
    "#### 3.1 comportamenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "polished-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+-----------------------+\n",
      "|id_utente|Partner_erogante|sum(reward(tk))|count(Partner_erogante)|\n",
      "+---------+----------------+---------------+-----------------------+\n",
      "| CA_10003|           CONAD|           2.55|                      1|\n",
      "| CA_10003|            HERA|            5.7|                      2|\n",
      "| CA_10003|           CAMST|            4.8|                      2|\n",
      "| CA_10007|            HERA|            6.2|                      3|\n",
      "| CA_10007|           CONAD|           2.55|                      1|\n",
      "+---------+----------------+---------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comportamenti.groupBy(comportamenti.id_utente, comportamenti.Partner_erogante).agg({'reward(tk)':'sum', 'Partner_erogante':'count'}).sort(comportamenti.id_utente).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-upset",
   "metadata": {},
   "source": [
    "#### 3.2 premi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "organic-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------------------+---------------+\n",
      "|id_utente|Partner_erogante|count(Partner_erogante)|sum(prezzo(tk))|\n",
      "+---------+----------------+-----------------------+---------------+\n",
      "|         |           CONAD|                   9698|          96980|\n",
      "|         |            HERA|                   9615|          96150|\n",
      "| CA_10003|           CONAD|                      2|             10|\n",
      "|  CA_1001|           CAMST|                      1|              5|\n",
      "|  CA_1001|           CONAD|                      4|             25|\n",
      "+---------+----------------+-----------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "premi.groupBy(premi.id_utente, premi.Partner_erogante).agg({'prezzo(tk)':'sum', 'Partner_erogante':'count'}).sort(premi.id_utente).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "optional-techno",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440123"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "special-latex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29555"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = utenti.filter(a['Eta'] < 20)\n",
    "b.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a temporary view using the DataFrame\n",
    "utenti.createOrReplaceTempView(\"utenti\")\n",
    "teenagerNamesDF = spark.sql(\"SELECT id_utente FROM utenti WHERE Eta BETWEEN 13 AND 19\")\n",
    "teenagerNamesDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-greek",
   "metadata": {},
   "source": [
    "### 4. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-owner",
   "metadata": {},
   "source": [
    "### 5. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=2)\n",
    "kmeans.setSeed(1)\n",
    "kmeans.setMaxIter(10)\n",
    "kmeans.getMaxIter()\n",
    "\n",
    "df = peopleDF['id_utente', 'reward(tk)'].groupBy(\"id_utente\").sum()\n",
    "\n",
    "model = kmeans.fit(df)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import time\n",
    "\n",
    "# Create the PipelineOptions\n",
    "options = PipelineOptions([\n",
    "\"--runner=DirectRunner\",          #Portable Runner is needed to execute a Python Apache Beam pipeline on Spark\n",
    "\"--job_endpoint=localhost:8099\",    #The job endpoint is the JobService, so the central instance where you submit your Beam pipeline. The JobService will create a Spark job for the pipeline and execute the job.\n",
    "# \"--environment_type=LOOPBACK\",\n",
    "\"--hdfs_host=my-hdfs-namenodes\",\n",
    "\"--hdfs_port=8020\",\n",
    "\"--hdfs_user=lori\"\n",
    "])\n",
    "with beam.Pipeline(options=options) as p:\n",
    "    lines = (\n",
    "        p \n",
    "        | beam.io.ReadFromText('hdfs://my-hdfs-namenodes:9870/HeraSDG/raw_data/comportamenti/2021/03/24/11/*.json') \n",
    "        | 'Print contents' >> beam.Map(print)\n",
    "    )\n",
    "#     output = (\n",
    "#         p\n",
    "#         | 'Create mock values' >> beam.Create([1,2,3,4,5,6])\n",
    "#         | 'Sum all values' >> beam.CombineGlobally(sum)\n",
    "#     )\n",
    "#     output | beam.io.WriteToText(FlatMap(print)\n",
    "\n",
    "#     output | beam.io.hadoopfilesystem.HadoopFileSystem._list(\"hdfs://funziona.txt\")\n",
    "# hdfs = beam.io.hadoopfilesystem.HadoopFileSystem(options)\n",
    "# hdfs.create(\"hdfs://funziona.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
